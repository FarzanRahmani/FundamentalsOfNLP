{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz2hmZ6tThNp"
      },
      "source": [
        "1.Submit a Google Colab notebook containing your completed code and experimentation results.\n",
        "\n",
        "2.Include comments and explanations in your code to help understand the implemented logic.\n",
        "\n",
        "**Additional Notes:**\n",
        "*   Ensure that the notebook runs successfully in Google Colab.\n",
        "*   Document any issues encountered during experimentation and how you addressed them.\n",
        "\n",
        "**Grading:**\n",
        "*   Each task will be graded out of the specified points.\n",
        "*   Points will be awarded for correctness, clarity of code, thorough experimentation, and insightful analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoUu86p1Or1n"
      },
      "source": [
        "# Prediction-Based Word Vectors\n",
        "\n",
        "more recently prediction-based word vectors have demonstrated better performance, such as word2vec and GloVe (which also utilizes the benefit of counts). Here, we shall explore the embeddings produced by GloVe.\n",
        "\n",
        "Then run the following cells to load the GloVe vectors into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvpYg_7pODYJ",
        "outputId": "30312ebe-2eab-4748-ab95-44c78d15de34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 252.1/252.1MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "import pprint\n",
        "wv_from_bin = api.load(\"glove-wiki-gigaword-200\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFfCOLUsSSuS"
      },
      "source": [
        "### Words with Multiple Meanings\n",
        "Polysemes and homonyms are words that have more than one meaning (see this [wiki page](https://en.wikipedia.org/wiki/Polysemy) to learn more about the difference between polysemes and homonyms ). Find a word with *at least two different meanings* such that the top-10 most similar words (according to cosine similarity) contain related words from *both* meanings. For example, \"leaves\" has both \"go_away\" and \"a_structure_of_a_plant\" meaning in the top 10, and \"scoop\" has both \"handed_waffle_cone\" and \"lowdown\". You will probably need to try several polysemous or homonymic words before you find one.\n",
        "\n",
        "Please state the word you discover and the multiple meanings that occur in the top 10. Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain **one** of the meanings of the words)?\n",
        "\n",
        "**Note**: You should use the `wv_from_bin.most_similar(word)` function to get the top 10 similar words. This function ranks all other words in the vocabulary with respect to their cosine similarity to the given word. For further assistance, please check the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.most_similar)__."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I will try the word \"orange\", which can mean\n",
        "# 1. a round fruit that has a thick orange skin and is divided into parts inside\n",
        "# 2. a bright colour that is between red and yellow\n",
        "# The all top 10 most similar words contain words related to colour meanings, such as \"yellow\",\n",
        "#  \"green\", \"red\", etc. (2. a bright colour that is between red and yellow),\n",
        "#  and not fruit meaning!\n",
        "\n",
        "word = \"orange\"\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word)\n",
        "print(f\"Top 10 similar words to '{word}':\")\n",
        "pprint.pprint(top_10_similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoqmNpjOBEXA",
        "outputId": "c3301056-f9b0-476f-b0b0-85f875ecb8cb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 similar words to 'orange':\n",
            "[('yellow', 0.6376613974571228),\n",
            " ('green', 0.6299034953117371),\n",
            " ('red', 0.6169558167457581),\n",
            " ('colored', 0.5946165323257446),\n",
            " ('blue', 0.5932760238647461),\n",
            " ('bright', 0.5708632469177246),\n",
            " ('black', 0.5666570067405701),\n",
            " ('pink', 0.5529779195785522),\n",
            " ('purple', 0.5495959520339966),\n",
            " ('colors', 0.5354291200637817)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAr09U-xSSuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ac7610-afa4-4988-ab21-9788ed77ca6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 similar words to 'bat':\n",
            "[('bats', 0.691724419593811),\n",
            " ('batting', 0.6160588264465332),\n",
            " ('balls', 0.5692734122276306),\n",
            " ('batted', 0.5530908107757568),\n",
            " ('toss', 0.5506128668785095),\n",
            " ('wicket', 0.5495278835296631),\n",
            " ('pitch', 0.5489361882209778),\n",
            " ('bowled', 0.5452010631561279),\n",
            " ('hitter', 0.5353438854217529),\n",
            " ('batsman', 0.5348091125488281)]\n"
          ]
        }
      ],
      "source": [
        "# I will try the word \"bat\", which can mean\n",
        "# 1. a flying mammal\n",
        "# 2. a sports equipment used in baseball.\n",
        "# we can see both meanings are present in the top 10 similar words.\n",
        "# we can see word \"bats\" which is related to meaning '1. a flying mammal'\n",
        "# other meanings are related to baseball (2. a sports equipment used in baseball.) such as \"balls\", \"toss\", \"wicket\", etc.\n",
        "word = \"bat\"\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word)\n",
        "print(f\"Top 10 similar words to '{word}':\")\n",
        "pprint.pprint(top_10_similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I will try the word \"bank\", which can mean\n",
        "# 1. a financial institution\n",
        "# 2. the sloped land beside a river.\n",
        "# The all top 10 most similar words contain words related to meanings, such as \"lending\",\n",
        "# \"mortgage\", \"loan\" (financial meaning), and not \"riverside\", \"shoreline\" (geographical meaning)!\n",
        "\n",
        "word = \"bank\"\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word)\n",
        "print(f\"Top 10 similar words to '{word}':\")\n",
        "pprint.pprint(top_10_similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBTkGt41iDyd",
        "outputId": "8f184cd1-0e60-4be9-e826-71e6f05f53c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 similar words to 'bank':\n",
            "[('banks', 0.7625691294670105),\n",
            " ('banking', 0.6818838119506836),\n",
            " ('central', 0.6283639073371887),\n",
            " ('financial', 0.6166563034057617),\n",
            " ('credit', 0.6049750447273254),\n",
            " ('lending', 0.5980608463287354),\n",
            " ('monetary', 0.5963003039360046),\n",
            " ('bankers', 0.5913101434707642),\n",
            " ('loans', 0.5802939534187317),\n",
            " ('investment', 0.5740203261375427)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I will try the word \"plants\", which can mean\n",
        "# 1. a factory or building where an industrial process happens\n",
        "# 2. a living thing that has leaves and roots and grows in earth, especially one that is smaller than a tree\n",
        "# we can see both meanings are present in the top 10 similar words.\n",
        "# 1. we can see words which are related to meaning '1.  a factory or building where an industrial process\n",
        "#     happens' such as \"produce\", \"factories\", \"producing\"\n",
        "# 2. we can also see words which are related to meaning '2. a living thing that has leaves and roots and grows in earth,\n",
        "#     especially one that is smaller than a tree' such as \"flowering\", \"trees\", \"species\" , \"shrubs\", \"varieties\", \"crops\"\n",
        "\n",
        "word = \"plants\"\n",
        "\n",
        "top_10_similar_words = wv_from_bin.most_similar(word)\n",
        "print(f\"Top 10 similar words to '{word}':\")\n",
        "pprint.pprint(top_10_similar_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC4kXY7ujtIN",
        "outputId": "6901982c-843b-4667-f525-3ec89ca917b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 similar words to 'plants':\n",
            "[('plant', 0.8802076578140259),\n",
            " ('flowering', 0.5858912467956543),\n",
            " ('produce', 0.5733449459075928),\n",
            " ('factories', 0.5709850788116455),\n",
            " ('trees', 0.5704270005226135),\n",
            " ('species', 0.5589885711669922),\n",
            " ('shrubs', 0.5408827662467957),\n",
            " ('varieties', 0.5284178853034973),\n",
            " ('producing', 0.5240455269813538),\n",
            " ('crops', 0.5226603746414185)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdQ018tjSSuT"
      },
      "source": [
        "### SOLUTION\n",
        "I tried the word \"plants\", which can mean\n",
        "1. a factory or building where an industrial process happens\n",
        "2.  a living thing that has leaves and roots and grows in earth, especially one that is smaller than a tree.\n",
        "\n",
        "we saw both meanings are present in the top 10 similar\n",
        "words:\n",
        "* we saw words which are related to meaning '1.  a factory or building where an industrial process happens' such as \"produce\", \"factories\", \"producing\" .\n",
        "* we also saw words which are related to meaning '2. a living thing that has leaves and roots and grows in earth, especially one that is smaller than a tree' such as \"flowering\", \"trees\", \"species\" , \"shrubs\", \"varieties\", \"crops\".\n",
        "\n",
        "Why do you think many of the polysemous or homonymic words you tried didn't work (i.e. the top-10 most similar words only contain one of the meanings of the words)?\n",
        "\n",
        "Many polysemous or homonymic words didn't work because the GloVe embeddings tend to represent the most common or dominant meaning of a word. The less frequent meanings may not be well-represented in the top-10 similar words. Additionally, the embeddings are learned from co-occurrence statistics in the training corpus, which may not capture all possible meanings of a word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfeW-eK9SSuU"
      },
      "source": [
        "### Synonyms & Antonyms\n",
        "\n",
        "When considering Cosine Similarity, it's often more convenient to think of Cosine Distance, which is simply 1 - Cosine Similarity.\n",
        "\n",
        "Find three words $(w_1,w_2,w_3)$ where $w_1$ and $w_2$ are synonyms and $w_1$ and $w_3$ are antonyms, but Cosine Distance $(w_1,w_3) <$ Cosine Distance $(w_1,w_2)$.\n",
        "\n",
        "As an example, $w_1$=\"happy\" is closer to $w_3$=\"sad\" than to $w_2$=\"cheerful\". Please find a different example that satisfies the above. Once you have found your example, please give a possible explanation for why this counter-intuitive result may have happened.\n",
        "\n",
        "You should use the the `wv_from_bin.distance(w1, w2)` function here in order to compute the cosine distance between two words. Please see the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.FastTextKeyedVectors.distance)__ for further assistance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwlpPjpHSSuV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e6f2c5c-39d7-41d8-bc2d-4c57de964f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synonyms small, tiny have cosine distance: 0.2600187659263611\n",
            "Antonyms small, large have cosine distance: 0.1497916579246521\n"
          ]
        }
      ],
      "source": [
        "# w1 = \"happy\"\n",
        "# w2 = \"cheerful\"\n",
        "# w3 = \"sad\"\n",
        "w1 = \"small\"\n",
        "w2 = \"tiny\"\n",
        "w3 = \"large\"\n",
        "w1_w2_dist = wv_from_bin.distance(w1, w2)\n",
        "w1_w3_dist = wv_from_bin.distance(w1, w3)\n",
        "\n",
        "print(\"Synonyms {}, {} have cosine distance: {}\".format(w1, w2, w1_w2_dist))\n",
        "print(\"Antonyms {}, {} have cosine distance: {}\".format(w1, w3, w1_w3_dist))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeIHjTFMSSuV"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "In this example, \"small\" and \"tiny\" are synonyms, while \"small\" and \"large\" are antonyms. However, the cosine distance between \"small\" and \"large\" (antonym) is smaller than the cosine distance between \"small\" and \"tiny\" (synonym).\n",
        "\n",
        "This counter-intuitive result may have happened because the word embeddings are learned from co-occurrence patterns in the training corpus. The corpus may contain more contexts where \"small\" and \"large\" co-occur together (e.g., \"The small house and the large house were on the same street\"), which can make their embeddings more similar than expected. On the other hand, \"small\" and \"tiny\" may not co-occur as frequently, leading to less similar embeddings.\n",
        "\n",
        "Additionally, the word embeddings may capture certain nuanced differences in meaning or usage between \"small\" and \"tiny\" that are not immediately apparent, resulting in a larger cosine distance between them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxIDq26zSSuW"
      },
      "source": [
        "### Analogies with Word Vectors\n",
        "Word vectors have been shown to *sometimes* exhibit the ability to solve analogies.\n",
        "\n",
        "As an example, for the analogy \"man : grandfather :: woman : x\" (read: man is to grandfather as woman is to x), what is x?\n",
        "\n",
        "In the cell below, we show you how to use word vectors to find x using the `most_similar` function from the __[GenSim documentation](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.KeyedVectors.most_similar)__. The function finds words that are most similar to the words in the `positive` list and most dissimilar from the words in the `negative` list. The answer to the analogy will have the highest cosine similarity (largest returned numerical value)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0pC7H4VSSuY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6d9c9a-7f2e-44ba-9310-1d1fd394a23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('grandmother', 0.7608445286750793),\n",
            " ('granddaughter', 0.7200808525085449),\n",
            " ('daughter', 0.7168302536010742),\n",
            " ('mother', 0.7151536345481873),\n",
            " ('niece', 0.7005682587623596),\n",
            " ('father', 0.6659887433052063),\n",
            " ('aunt', 0.6623408794403076),\n",
            " ('grandson', 0.6618767976760864),\n",
            " ('grandparents', 0.644661009311676),\n",
            " ('wife', 0.6445354223251343)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to answer the analogy -- man : grandfather :: woman : x\n",
        "# x = grandfather - man + woman = +grandfather -man +woman --> positive=['woman', 'grandfather'], negative=['man']\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'grandfather'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVv8I9WwSSuZ"
      },
      "source": [
        "Let $m$, $g$, $w$, and $x$ denote the word vectors for `man`, `grandfather`, `woman`, and the answer, respectively. Using **only** vectors $m$, $g$, $w$, and the vector arithmetic operators $+$ and $-$ in your answer, to what expression are we maximizing $x$'s cosine similarity?\n",
        "\n",
        "Hint: Recall that word vectors are simply multi-dimensional vectors that represent a word. It might help to draw out a 2D example using arbitrary locations of each vector. Where would `man` and `woman` lie in the coordinate plane relative to `grandfather` and the answer?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlUKBqtHSSuZ"
      },
      "source": [
        "### SOLUTION\n",
        "### x = grandfather - man + woman\n",
        "\n",
        "To solve the analogy \"man : grandfather :: woman : x\", we want to find a vector x that is related to the vector for \"woman\" in the same way that \"grandfather\" is related to \"man\". In other words, we want to find x such that x - w = g - m.\n",
        "\n",
        "Rearranging the equation, we get:\n",
        "x = w + (g - m)\n",
        "\n",
        "So, we are maximizing the cosine similarity of x with the expression w + (g - m), which represents the vector obtained by adding the vector displacement from \"man\" to \"grandfather\" to the vector for \"woman\".\n",
        "\n",
        "(We are maximizing x's cosine similarity by maximizing the cosine similarity between \"woman\" and \"x\",\n",
        "while minimizing the cosine similarity between \"man\" and \"woman\" and maximizing the cosine similarity between \"man\" and \"grandfather\".\n",
        "This effectively results in minimizing the angle between \"woman\" and \"x\" vectors, leading to a higher cosine similarity.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rRgMca9SSua"
      },
      "source": [
        "### Finding Analogies\n",
        "a. For the previous example, it's clear that \"grandmother\" completes the analogy. But give an intuitive explanation as to why the `most_similar` function gives us words like \"granddaughter\", \"daughter\", or \"mother?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgYQXazQSSua"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "The `most_similar` function ranks words based on their cosine similarity to the target vector, which in this case is the result of w + (g - m). While \"grandmother\" is the most similar word, words like \"granddaughter\", \"daughter\", and \"mother\" are also highly similar because they are related to the family/kinship domain and share some semantic and co-occurrence patterns with the words in the analogy.\n",
        "\n",
        "Also, The `most_similar` function finds words similar to 'woman' and 'grandfather' while being dissimilar to 'man'. This can include relatives related to 'grandfather' like 'grandmother' or 'daughter' that are also associated with women."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9aAUXEISSub"
      },
      "source": [
        "b. Find an example of analogy that holds according to these vectors (i.e. the intended word is ranked top). In your solution please state the full analogy in the form x:y :: a:b. If you believe the analogy is complicated, explain why the analogy holds in one or two sentences.\n",
        "\n",
        "**Note**: You may have to try many analogies to find one that works!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "dhzQJMYYVSjf"
      },
      "outputs": [],
      "source": [
        "x, y, a, b = \"king\", \"queen\", \"man\", \"woman\"\n",
        "# x, y, a, b = \"apple\", \"red\", \"lemon\", \"yellow\" # works\n",
        "# x, y, a, b = \"iran\", \"tehran\", \"iraq\", \"baghdad\" # works\n",
        "\n",
        "assert wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0] == b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3QlPqAwSSub"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "The analogy \"king:queen :: man:woman\" holds according to the word vectors. This analogy captures the gender relationship between \"king\" and \"queen\", which is similar to the gender relationship between \"man\" and \"woman\". The embeddings have learned these semantic and linguistic patterns from the co-occurrence statistics in the training corpus.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwgcEywwSSuc"
      },
      "source": [
        "### Incorrect Analogy\n",
        "a. Below, we expect to see the intended analogy \"hand : glove :: foot : **sock**\", but we see an unexpected result instead. Give a potential reason as to why this particular analogy turned out the way it did?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-ykWoJoSSuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ccdc66-4a00-4795-8c70-00a96c26a14a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('45,000-square', 0.4922032654285431),\n",
            " ('15,000-square', 0.4649604558944702),\n",
            " ('10,000-square', 0.4544755816459656),\n",
            " ('6,000-square', 0.44975775480270386),\n",
            " ('3,500-square', 0.444133460521698),\n",
            " ('700-square', 0.44257497787475586),\n",
            " ('50,000-square', 0.4356396794319153),\n",
            " ('3,000-square', 0.43486514687538147),\n",
            " ('30,000-square', 0.4330596923828125),\n",
            " ('footed', 0.43236875534057617)]\n"
          ]
        }
      ],
      "source": [
        "pprint.pprint(wv_from_bin.most_similar(positive=['foot', 'glove'], negative=['hand']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn4ruS8MSSud"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "The analogy \"hand : glove :: foot : sock\" does not hold according to the word vectors. Instead, we get words like \"45,000-square\" and \"15,000-square\" as the top results. This could be because the training corpus may not have enough co-occurrences of \"foot\" and \"sock\" in similar contexts as \"hand\" and \"glove\". The word embeddings may have learned that \"45,000-square\" and \"15,000-square\" are more closely associated with \"foot\" than \"sock\" based on the co-occurrence statistics in the corpus.\n",
        "Because the foot is a unit for measuring the area, and it is possible that the size and area of ​​countries, cities, stadiums, oceans, etc. have come together in the training corpus. This multi-meaning of the word(polysemes) \"foot\" creates this problem, and in fact, because GloVe assigns only one vector to each word, it cannot well understand the linguistic nuances of words with multiple meanings such as foot.\n",
        "\n",
        "The reason this particular analogy turned out the way it did could be because “glove” and “sock” are not used in the same contexts in the training corpus. For example, \"foot\" is used as a unit for measuring area of places, “glove” might be used more often in contexts related to boxing or safety equipment, while “sock” might be used more often in everyday contexts. This difference in usage could lead to their word vectors being located in different parts of the vector space, resulting in an unexpected result for the analogy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1gHyZt0SSud"
      },
      "source": [
        "b. Find another example of analogy that does *not* hold according to these vectors. In your solution, state the intended analogy in the form x:y :: a:b, and state the **incorrect** value of b according to the word vectors (in the previous example, this would be **'45,000-square'**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "D_rlci42XQTw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d70e23-e965-435f-8a0f-01aef65592be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intended analogy: day:light :: night:dark\n",
            "Incorrect answer according to word vectors: lights\n"
          ]
        }
      ],
      "source": [
        "# x, y, a, b = \"good\", \"better\", \"bad\", \"worse\" # did not work\n",
        "# x, y, a, b = \"big\", \"bigger\", \"small\", \"smaller\" # did not work\n",
        "x, y, a, b = \"day\", \"light\", \"night\", \"dark\" # works\n",
        "# pprint.pprint(wv_from_bin.most_similar(positive=[a, y], negative=[x]))\n",
        "incorrect_answer = wv_from_bin.most_similar(positive=[a, y], negative=[x])[0][0]\n",
        "print(f\"Intended analogy: {x}:{y} :: {a}:{b}\")\n",
        "print(f\"Incorrect answer according to word vectors: {incorrect_answer}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4x0EHjeSSue"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "Another example of an analogy that does not hold according to these vectors could be \"day : light :: night : dark\". The intended analogy is \"day is to light as night is to dark\", but the word vectors give an incorrect value for \"dark\" which is \"lights\".\n",
        "This can be caused by the more co-occurrence of these words in the dataset of training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvlycXN-SSuf"
      },
      "source": [
        "### Guided Analysis of Bias in Word Vectors\n",
        "\n",
        "It's important to be cognizant of the biases (gender, race, sexual orientation etc.) implicit in our word embeddings. Bias can be dangerous because it can reinforce stereotypes through applications that employ these models.\n",
        "\n",
        "Run the cell below, to examine (a) which terms are most similar to \"woman\" and \"profession\" and most dissimilar to \"man\", and (b) which terms are most similar to \"man\" and \"profession\" and most dissimilar to \"woman\". Point out the difference between the list of female-associated words and the list of male-associated words, and explain how it is reflecting gender bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XggWA4MhSSuf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54d1887-a3bc-43b2-f1ae-85ec2bdf32a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('reputation', 0.5250176787376404),\n",
            " ('professions', 0.5178037881851196),\n",
            " ('skill', 0.49046966433525085),\n",
            " ('skills', 0.49005505442619324),\n",
            " ('ethic', 0.4897659420967102),\n",
            " ('business', 0.4875852167606354),\n",
            " ('respected', 0.485920250415802),\n",
            " ('practice', 0.482104629278183),\n",
            " ('regarded', 0.4778572618961334),\n",
            " ('life', 0.4760662019252777)]\n",
            "\n",
            "[('professions', 0.5957457423210144),\n",
            " ('practitioner', 0.49884122610092163),\n",
            " ('teaching', 0.48292139172554016),\n",
            " ('nursing', 0.48211804032325745),\n",
            " ('vocation', 0.4788965880870819),\n",
            " ('teacher', 0.47160351276397705),\n",
            " ('practicing', 0.46937814354896545),\n",
            " ('educator', 0.46524327993392944),\n",
            " ('physicians', 0.4628995358943939),\n",
            " ('professionals', 0.4601394236087799)]\n"
          ]
        }
      ],
      "source": [
        "# Run this cell\n",
        "# Here `positive` indicates the list of words to be similar to and `negative` indicates the list of words to be most dissimilar from.\n",
        "\n",
        "# x = profession + (man - woman)\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['man', 'profession'], negative=['woman']))\n",
        "print()\n",
        "# x = profession + (woman - man)\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=['woman', 'profession'], negative=['man']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4g6KbsYSSuh"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "The list of words most similar to \"man\" and \"profession\" but dissimilar to \"woman\" contains words like \"business\", \"respected\", \"reputation\", \"skills\" which are typically associated with male-dominated professions.\n",
        "\n",
        "On the other hand, the list of words most similar to \"woman\" and \"profession\" but dissimilar to \"man\" contains words like \"practitioner\", \"nursing\", \"teacher\", which are traditionally seen as female-dominated professions.\n",
        "\n",
        "This reflects the gender bias present in the word embeddings, where certain professions are more strongly associated with either men or women, based on the co-occurrence patterns and biases present in the training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxJmnS6lSSui"
      },
      "source": [
        "### Independent Analysis of Bias in Word Vectors\n",
        "\n",
        "Use the `most_similar` function to find another pair of analogies that demonstrates some bias is exhibited by the vectors. Please briefly explain the example of bias that you discover."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZoDheIfSSui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9c074b-d5e9-4f00-fb4a-874d9e61c0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('dr.', 0.5486297011375427),\n",
            " ('physician', 0.5327187776565552),\n",
            " ('he', 0.5275285243988037),\n",
            " ('him', 0.5230658054351807),\n",
            " ('himself', 0.5116503238677979),\n",
            " ('medical', 0.5046804547309875),\n",
            " ('his', 0.5044267177581787),\n",
            " ('brother', 0.503484845161438),\n",
            " ('surgeon', 0.5005415678024292),\n",
            " ('mr.', 0.4938008189201355)]\n",
            "\n",
            "[('nurse', 0.6813318729400635),\n",
            " ('physician', 0.6672453284263611),\n",
            " ('doctors', 0.6173422336578369),\n",
            " ('dentist', 0.5775880217552185),\n",
            " ('surgeon', 0.5691418647766113),\n",
            " ('hospital', 0.564996600151062),\n",
            " ('pregnant', 0.5649074912071228),\n",
            " ('nurses', 0.5590692758560181),\n",
            " ('medical', 0.5542059540748596),\n",
            " ('patient', 0.5518484711647034)]\n"
          ]
        }
      ],
      "source": [
        "# A = \"white\"\n",
        "# B = \"black\"\n",
        "# word = \"pleasant\"\n",
        "# In this example, we can observe racial bias in the word embeddings. When we find words similar to \"white\" and\n",
        "# \"pleasant\" but dissimilar to \"black\", we get words like \"delightful\", \"lovely\", \"wonderful\", which have positive connotations.\n",
        "# On the other hand, when we find words similar to \"black\" and \"pleasant\" but dissimilar to \"white\", we get words\n",
        "#  like \"poisonous\", \"disgusting\", \"dirty\", which have negative connotations.\n",
        "# This bias reflects the inherent racial biases present in the training data, where \"white\" is more strongly\n",
        "#  associated with positive attributes, while \"black\" is more strongly associated with negative attributes.\n",
        "\n",
        "A = \"man\"\n",
        "B = \"woman\"\n",
        "word = \"doctor\"\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[A, word], negative=[B])) # x = doctor + (man - woman)\n",
        "print()\n",
        "pprint.pprint(wv_from_bin.most_similar(positive=[B, word], negative=[A])) # x = doctor + (woman - man)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGOlmtJoSSuj"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "An example of bias could be \"man : doctor :: woman : nurse\". This analogy demonstrates gender bias in the profession, implying that men are more likely to be doctors and women are more likely to be nurses."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eK2XVWzmSSuk"
      },
      "source": [
        "### Thinking About Bias\n",
        "\n",
        "a. Give one explanation of how bias gets into the word vectors. Briefly describe a real-world example that demonstrates this source of bias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19pM85fCSSuk"
      },
      "source": [
        "### SOLUTION\n",
        "\n",
        "Bias gets into the word vectors through the training data. If the text data used to train the word vectors contains biases, such as gender or racial stereotypes, these biases will be reflected in the word vectors. For example, if the training data often uses male pronouns for certain professions and female pronouns for others, the resulting word vectors will reflect this bias.\n",
        "\n",
        "In other words, One way bias gets into word vectors is through the training data itself. If the text corpus used to train the word embeddings contains biases, stereotypes, or imbalanced representations of certain groups, these biases will be encoded into the learned word vectors.\n",
        "\n",
        "For example, if the training corpus consists of a large number of news articles or books written predominantly by and about white, male authors, the word embeddings may reflect biases and stereotypes present in those texts, associating certain professions, traits, or attributes more strongly with white men than with other groups.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILYqJZ7ASSul"
      },
      "source": [
        "b. What is one method you can use to mitigate bias exhibited by word vectors?  Briefly describe a real-world example that demonstrates this method."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnJaAB7mSSul"
      },
      "source": [
        "\n",
        "### SOLUTION\n",
        "\n",
        "One method to mitigate bias exhibited by word vectors is debiasing techniques, such as the one proposed by Bolukbasi et al., 2016. They proposed a method to remove gender bias from word vectors by neutralizing gender-specific words and equalizing gender-neutral words. These involve identifying and removing specific biases from the word embeddings through mathematical transformations or constraint-based optimization.\n",
        "\n",
        "For example, the \"Hard Debiased\" method aims to remove gender stereotypes from word embeddings by enforcing certain constraints during training, such as ensuring that gender-neutral words like \"doctor\" or \"engineer\" are equidistant from the embeddings of \"man\" and \"woman\". And also, the words “nurse” and “engineer” should be equidistant from “she” and “he” in the vector space after debiasing.\n",
        "\n",
        "In a real-world application like resume screening or job recommendation systems, using debiased word embeddings can help reduce gender biases and ensure that job recommendations are made based on relevant skills and qualifications rather than stereotypical gender associations.\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}