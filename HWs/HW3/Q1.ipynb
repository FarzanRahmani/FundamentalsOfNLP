{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QK-0syxkWi21"
      },
      "source": [
        "# Q1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX0LV_hrWPsG"
      },
      "source": [
        "\n",
        "*   In this question we want to use POS-tagged training set to compute for each word the tag that maximizes $p(t|w)$.\n",
        "*   We will implement a simple tokenizer to deal with sentence boundaries.\n",
        "*   We start by assuming that all unknown words are NN and compute error rate on known and unknown words.\n",
        "*   Then write at least five rules to do a better job of tagging unknown words, and show the difference in error rates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lueYCsOI0WgG",
        "outputId": "a765d962-5920-40c3-c02e-b67f2c1438bf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import math\n",
        "\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "from nltk.corpus import brown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ppIGG8ZWv1c"
      },
      "outputs": [],
      "source": [
        "def generate_dict(_samples):\n",
        "    \"\"\"\n",
        "    Generate a dictionary that captures the count of each (word, tag) combination from a list of samples.\n",
        "\n",
        "    Args:\n",
        "    _samples (list): List of tuples containing (word, tag) pairs.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where keys are words and values are lists of dictionaries with 'tag' and 'count' keys.\n",
        "          Each dictionary in the list represents a unique tag associated with the word and its count.\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    Example:\n",
        "      _samples = [('apple', 'fruit'), ('banana', 'fruit'), ('apple', 'fruit'), ('apple', 'color'), ('banana', 'color')]\n",
        "      After calling generate_dict(_samples), the expected output would be:\n",
        "      {\n",
        "          'apple': [\n",
        "              {'tag': 'fruit', 'count': 2},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ],\n",
        "          'banana': [\n",
        "              {'tag': 'fruit', 'count': 1},\n",
        "              {'tag': 'color', 'count': 1}\n",
        "          ]\n",
        "      }\n",
        "      This represents that 'apple' appeared twice with the tag 'fruit' and once with the tag 'color',\n",
        "      while 'banana' appeared once with both 'fruit' and 'color' tags.\n",
        "\n",
        "    '''\n",
        "\n",
        "    dictionary = {}\n",
        "\n",
        "\n",
        "    ## Your code here\n",
        "    # create the dictionary described in the comments\n",
        "    for word, tag in _samples:\n",
        "        if word not in dictionary:\n",
        "            dictionary[word] = [{'tag': tag, 'count': 1}]\n",
        "        else:\n",
        "            found = False\n",
        "            for item in dictionary[word]:\n",
        "                if item['tag'] == tag:\n",
        "                    item['count'] += 1\n",
        "                    found = True\n",
        "                    break\n",
        "            if not found:\n",
        "                dictionary[word].append({'tag': tag, 'count': 1})\n",
        "\n",
        "    ## End Code\n",
        "    def get_tag_counts(subitem):\n",
        "        return subitem['count']\n",
        "\n",
        "    for item in dictionary:\n",
        "        # dictionary['banana'] =\n",
        "        #         {'tag': 'fruit', 'count': 1},\n",
        "        #         {'tag': 'color', 'count': 1}\n",
        "        sorted(dictionary[item], key=get_tag_counts, reverse=True)\n",
        "\n",
        "    return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-wu5AVoX_rN"
      },
      "outputs": [],
      "source": [
        "def predict_tag(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag)=(x, y) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is assigned.\n",
        "    - Tags are assigned based on the highest count for known words.\n",
        "      - If there are more than 1 tag for a given word, the tag with the highest count is chosen.\n",
        "      - If there is only 1 tag available, it is returned directly.\n",
        "    \"\"\"\n",
        "\n",
        "    accuracy = 0\n",
        "    for item in _test_set: # item = (word, true_tag)\n",
        "        word = item[0]\n",
        "        true_tag = item[1]\n",
        "        if word in _tag_dict:\n",
        "            prediction = _tag_dict[word][0]['tag']  # Choose the tag with the highest count\n",
        "        else:\n",
        "            prediction = 'NN'  # Assume unknown words as noun (NN)\n",
        "        if prediction == true_tag:\n",
        "          accuracy = accuracy + 1\n",
        "\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"Assuming that all unknown words are NN\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgXAgTDrcbYl"
      },
      "outputs": [],
      "source": [
        "def predict_tag_with_improvements(_test_set, _tag_dict):\n",
        "    \"\"\"\n",
        "    Predicts the tags for a given test set of words based on a provided tag dictionary, with additional rules for unknown words.\n",
        "\n",
        "    Args:\n",
        "    _test_set (list): A list of tuples containing (word, true_tag)=(x, y) pairs to be predicted.\n",
        "    _tag_dict (dict): A dictionary containing words as keys and lists of dictionaries with 'tag' and 'count' keys as values.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the predictions, calculated as the ratio of correct predictions to the total number of predictions.\n",
        "\n",
        "    Comments:\n",
        "    - For unknown words, 'NN' (noun) tag is initially assigned.\n",
        "    - Additional rules are applied to analyze unknown words and assign more specific tags based on patterns observed in the word:\n",
        "        - 'VBG' (verb, gerund) for words ending in 'ing'\n",
        "        - 'NP$' (noun, possessive) for words ending in \"'s\"\n",
        "        - 'NNS' (noun, plural) for words ending in 's'\n",
        "        - 'RB' (adverb) for words ending in 'ly'\n",
        "        - 'VBN' (verb, past participle) for words ending in 'ed'\n",
        "        - 'JJ' (adjective) for words matching certain patterns like 'ble', 'ish', 'ful', etc.\n",
        "        - 'CD' (cardinal numeral) for numeric strings\n",
        "        - 'NP' (noun, proper singular) for capitalized words\n",
        "    \"\"\"\n",
        "\n",
        "    ## Your code here\n",
        "    accuracy = 0\n",
        "    for word, true_tag in _test_set: # _test_set[i] = (word, true_tag) = (x, y)\n",
        "        if word in _tag_dict:\n",
        "            prediction = _tag_dict[word][0]['tag'] # Choose the tag with the highest count\n",
        "        else:\n",
        "            if word.endswith('ing'):\n",
        "                prediction = 'VBG'\n",
        "            elif word.endswith(\"'s\"):\n",
        "                prediction = 'NP$'\n",
        "            elif word.endswith('s'):\n",
        "                prediction = 'NNS'\n",
        "            elif word.endswith('ly'):\n",
        "                prediction = 'RB'\n",
        "            elif word.endswith('ed'):\n",
        "                prediction = 'VBN'\n",
        "            elif re.match(r'\\w+ble$', word) or re.match(r'\\w+ish$', word) or re.match(r'\\w+ful$', word):\n",
        "            # elif re.search(r'(ble|ish|ful)$', word):\n",
        "                prediction = 'JJ'\n",
        "            elif word.isdigit():\n",
        "                prediction = 'CD'\n",
        "            elif word[0].isupper():\n",
        "                prediction = 'NP'\n",
        "            else:\n",
        "                prediction = 'NN' # # Default to noun (NN) for unknown words\n",
        "\n",
        "        if prediction == true_tag:\n",
        "            accuracy += 1\n",
        "\n",
        "    ## End Code\n",
        "    accuracy /= len(_test_set)\n",
        "    print(f\"With additional rules for unknown words\")\n",
        "    print(f\">> accuracy: {accuracy}\")\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P6OX_pEh_tZ",
        "outputId": "e620bbcb-8936-4923-e694-8f12f51ca796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of training set:     75415\n",
            "length of testing set:      25139\n",
            "intersection:               3429\n",
            "-----------------------------------\n",
            "Assuming that all unknown words are NN\n",
            ">> accuracy: 0.8184096423883209\n",
            "With additional rules for unknown words\n",
            ">> accuracy: 0.8627630375114365\n",
            "1115 more words got correctly classified.\n"
          ]
        }
      ],
      "source": [
        "CORPUS = brown.tagged_words(categories='news')\n",
        "CORPUS_SIZE = len(brown.tagged_words(categories='news'))\n",
        "\n",
        "CUT_OFF = math.floor(CORPUS_SIZE * 0.75)\n",
        "\n",
        "# section off training and testing lists from corpus\n",
        "training_list = CORPUS[:CUT_OFF]\n",
        "testing_list = CORPUS[CUT_OFF:]\n",
        "\n",
        "# duplicates are ignored in sets\n",
        "training_set = set(training_list)\n",
        "testing_set = set(testing_list)\n",
        "intersection = training_set.intersection(testing_set)\n",
        "\n",
        "print(f\"length of training set:     {len(training_list)}\")\n",
        "print(f\"length of testing set:      {len(testing_list)}\")\n",
        "\n",
        "# uncomment to see how much the training set and testing set overlap\n",
        "print(f\"intersection:               {len(intersection)}\")\n",
        "\n",
        "# uncomment to survey tagged corpus\n",
        "# print(training_set)\n",
        "\n",
        "print(\"-----------------------------------\")\n",
        "\n",
        "tag_dict = generate_dict(training_list)\n",
        "accurary_base = predict_tag(testing_list, tag_dict)\n",
        "accurary_impr = predict_tag_with_improvements(testing_list, tag_dict)\n",
        "delta = math.floor((accurary_impr - accurary_base) * len(testing_list))\n",
        "print(f\"{delta} more words got correctly classified.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0EY8XNVirmv",
        "outputId": "83a6ed00-c92f-42ae-96de-56cfd80277de"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Holbrook', 'NP'),\n",
              " ('like', 'VB'),\n",
              " ('Norman', 'NP'),\n",
              " ('discussing', 'VBG'),\n",
              " ('Nautilus', 'NP'),\n",
              " ('policemen', 'NNS'),\n",
              " ('Explosion', 'NN-HL'),\n",
              " ('Johnston', 'NP'),\n",
              " ('$47,101,000', 'NNS'),\n",
              " ('Golden', 'JJ-TL'),\n",
              " ('Price', 'NP'),\n",
              " ('Jan.', 'NP'),\n",
              " ('allotted', 'VBD'),\n",
              " (\"Titche's\", 'NP$'),\n",
              " ('Displayed', 'VBN'),\n",
              " ('championship', 'NN'),\n",
              " ('vacation', 'NN'),\n",
              " ('pinch-hitters', 'NNS'),\n",
              " ('Lynn', 'NP'),\n",
              " ('desperate', 'JJ'),\n",
              " ('spree', 'NN'),\n",
              " ('oats', 'NN'),\n",
              " ('surgery', 'NN'),\n",
              " ('9', 'CD-TL'),\n",
              " ('died', 'VBD'),\n",
              " ('York-Pennsylvania', 'NP-TL'),\n",
              " ('weeks', 'NNS'),\n",
              " ('well', 'QL'),\n",
              " ('trims', 'NNS'),\n",
              " ('Hartford', 'NP'),\n",
              " ('chair', 'NN'),\n",
              " ('consonance', 'NN'),\n",
              " ('Week', 'NN'),\n",
              " ('Shrove', 'NP'),\n",
              " ('exposed', 'VBD'),\n",
              " ('Donnell', 'NP'),\n",
              " ('Clayton', 'NP'),\n",
              " ('racket', 'NN'),\n",
              " ('Snead', 'NP'),\n",
              " ('Corcoran', 'NP'),\n",
              " ('specialize', 'VB'),\n",
              " ('portable', 'JJ'),\n",
              " ('Century', 'NN-TL'),\n",
              " ('Bontempo', 'NP'),\n",
              " ('deeply', 'QL'),\n",
              " ('inclined', 'VBN'),\n",
              " ('Once', 'RB'),\n",
              " ('responding', 'VBG'),\n",
              " ('Tic-Tac-Toe', 'NP'),\n",
              " ('half-mile', 'NN'),\n",
              " ('totaling', 'VBG'),\n",
              " ('draft', 'VB'),\n",
              " ('apartments', 'NNS'),\n",
              " ('using', 'VBG'),\n",
              " ('checked', 'VBD'),\n",
              " ('assessments', 'NNS'),\n",
              " ('preserving', 'VBG'),\n",
              " ('sell', 'VB'),\n",
              " ('experienced', 'VBN'),\n",
              " ('Heilman', 'NP'),\n",
              " ('solos', 'NNS'),\n",
              " ('Kegham', 'NP'),\n",
              " ('Stranahan', 'NP-TL'),\n",
              " ('doubt', 'NN-HL'),\n",
              " ('Davis', 'NP'),\n",
              " ('bath', 'NN'),\n",
              " ('10-hour', 'JJ'),\n",
              " ('element', 'NN'),\n",
              " ('Stratton', 'NP'),\n",
              " ('grab', 'VB'),\n",
              " ('Marine', 'NN-TL'),\n",
              " ('western', 'JJ'),\n",
              " ('180', 'CD'),\n",
              " ('lead', 'NN'),\n",
              " ('Cain', 'NP-TL'),\n",
              " ('Students', 'NNS-HL'),\n",
              " ('clashes', 'NNS'),\n",
              " ('under', 'IN'),\n",
              " ('figures', 'VBZ'),\n",
              " ('redistricting', 'VBG'),\n",
              " ('Burnes', 'NP'),\n",
              " ('escort', 'NN'),\n",
              " ('counseled', 'VBD'),\n",
              " ('exchanged', 'VBN'),\n",
              " ('Probably', 'RB'),\n",
              " ('youngsters', 'NNS'),\n",
              " ('Boyce', 'NP'),\n",
              " ('Melcher', 'NP'),\n",
              " ('110', 'CD'),\n",
              " ('Vice-President', 'NN-TL'),\n",
              " ('Oslo', 'NP'),\n",
              " ('Screvane', 'NP-HL'),\n",
              " ('Shortly', 'RB'),\n",
              " ('expansive', 'JJ'),\n",
              " ('husband', 'NN'),\n",
              " ('read', 'VBD'),\n",
              " ('medal', 'NN'),\n",
              " ('head', 'NN'),\n",
              " ('Vivier', 'NP'),\n",
              " ('Investment', 'NN-TL')]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(training_set)\n",
        "list(training_set)[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# comparing the most frequent tag baseline versions.\n",
        "### 'Assuming that all unknown words are NN' versus 'With additional rules for unknown words' \n",
        "- most frequent tag baseline: `accuracy: 0.81841` (assuming all unknown words are 'NN')\n",
        "- improved most frequent tag baseline: `accuracy: 0.86276` (using the additional rules for unknown words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sA5h3pb-SOrO"
      },
      "source": [
        "# Analysis:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BPmNQQ7SR_m"
      },
      "source": [
        "### Steps we have gone through are:\n",
        "- Data Preparation: The Brown Corpus from the NLTK library is used for training and testing. It's divided into training and testing sets.\n",
        "- The generate_dict() function creates a dictionary where the keys are unique words, and the values are lists of dictionaries. Each dictionary in the list represents a unique tag associated with the word and its count.\n",
        "- The predict_tag() function uses the dictionary generated in the previous step to predict the tags for the test set. It assigns the 'NN' (noun) tag to unknown words and selects the tag with the highest count for known words.\n",
        "- The predict_tag_with_improvements() function builds on the previous one, adding more specific rules to handle unknown words. It checks for certain patterns in the word (e.g., ending in 'ing', 's', 'ly', 'ed', etc.) and assigns more appropriate tags based on these patterns.\n",
        "- The script first divides the Brown corpus (news category) into a training set (75%) and a testing set (25%). It then generates the tag dictionary from the training set and uses it to predict the tags for the testing set.\n",
        "- The initial accuracy, assuming all unknown words are 'NN', is printed.\n",
        "- The improved accuracy, using the additional rules for unknown words, is then printed.\n",
        "- The delta, which represents the number of more words that were correctly classified with the improved rules, is also printed.\n",
        "\n",
        "### The key observations from the results are:\n",
        "\n",
        "- The initial accuracy `which is 0.81841`, assuming all unknown words are 'NN', is a baseline that provides a starting point for comparison.\n",
        "- The improved accuracy `which is 0.86276`, using the additional rules for unknown words, shows an increase (approximately 5%) in performance.\n",
        "- The delta value `which is 1115` quantifies the improvement, indicating that the additional rules helped correctly classify a substantial number of words that were previously misclassified.\n",
        "\n",
        "### This analysis demonstrates the importance of developing more sophisticated rules and techniques to handle unknown words in part-of-speech tagging, which can lead to substantial improvements in the overall accuracy of the system."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
