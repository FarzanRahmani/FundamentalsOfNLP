{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgQDc4v3TfsF"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3BJFGcYT-LV"
      },
      "source": [
        "*   We will develop a NER system specific to the category of names of the top 1000 movie titles from IMDB.\n",
        "\n",
        "*   We will evaluate the system on a collection of text likely to contain instances of these named entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnwTjXyH5Xls",
        "outputId": "4a6586f2-b637-4fce-86ae-55f9a544f624"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3DlFdNPT95l",
        "outputId": "f8b77d60-a198-4229-b58c-d694061c5b10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import math\n",
        "import nltk\n",
        "nltk.download('brown')\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import brown, movie_reviews\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5hHLacEwzP3q"
      },
      "outputs": [],
      "source": [
        "def get_top_1000_list():\n",
        "    \"\"\"\n",
        "    Function to extract movie titles from a IMDB-top-1000.csv file.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of unique titles of the top 1000 movies\n",
        "    \"\"\"\n",
        "    collected_titles = []\n",
        "    with open('IMDB-top-1000.csv', 'r', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        next(reader)  # Skip the header\n",
        "        for row in reader:\n",
        "            # movie titles are in the second column\n",
        "            # for word in row[1].split(): # method 1\n",
        "            #     collected_titles.append(word)\n",
        "\n",
        "            collected_titles.append(row[1].split()) # method 2\n",
        "\n",
        "    # collected_titles = list(set(collected_titles))\n",
        "    collected_titles = sorted(collected_titles, key=lambda x: len(x), reverse=True)\n",
        "\n",
        "    return collected_titles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i3vwNLgT8bJ",
        "outputId": "c35e4cdc-afe7-4ff7-9b85-ab998459e756"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['Dr.',\n",
              "  'Strangelove',\n",
              "  'or:',\n",
              "  'How',\n",
              "  'I',\n",
              "  'Learned',\n",
              "  'to',\n",
              "  'Stop',\n",
              "  'Worrying',\n",
              "  'and',\n",
              "  'Love',\n",
              "  'the',\n",
              "  'Bomb'],\n",
              " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Return', 'of', 'the', 'King'],\n",
              " ['The',\n",
              "  'Lord',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Rings:',\n",
              "  'The',\n",
              "  'Fellowship',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Ring'],\n",
              " ['Pirates',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Caribbean:',\n",
              "  'The',\n",
              "  'Curse',\n",
              "  'of',\n",
              "  'the',\n",
              "  'Black',\n",
              "  'Pearl'],\n",
              " ['Star', 'Wars:', 'Episode', 'V', '-', 'The', 'Empire', 'Strikes', 'Back'],\n",
              " ['Star', 'Wars:', 'Episode', 'III', '-', 'Revenge', 'of', 'the', 'Sith'],\n",
              " ['The', 'Naked', 'Gun:', 'From', 'the', 'Files', 'of', 'Police', 'Squad!'],\n",
              " ['The', 'Lord', 'of', 'the', 'Rings:', 'The', 'Two', 'Towers'],\n",
              " ['Harry', 'Potter', 'and', 'the', 'Deathly', 'Hallows:', 'Part', '2'],\n",
              " ['Star', 'Wars:', 'Episode', 'VII', '-', 'The', 'Force', 'Awakens'],\n",
              " ['Harry', 'Potter', 'and', 'the', 'Deathly', 'Hallows:', 'Part', '1'],\n",
              " ['Fried', 'Green', 'Tomatoes', 'at', 'the', 'Whistle', 'Stop', 'Cafe'],\n",
              " ['The', 'Good,', 'the', 'Bad', 'and', 'the', 'Ugly'],\n",
              " ['Once', 'Upon', 'a', 'Time', 'in', 'the', 'West'],\n",
              " ['Lagaan:', 'Once', 'Upon', 'a', 'Time', 'in', 'India'],\n",
              " ['Neon', 'Genesis', 'Evangelion:', 'The', 'End', 'of', 'Evangelion'],\n",
              " ['Nausicaä', 'of', 'the', 'Valley', 'of', 'the', 'Wind'],\n",
              " ['4', 'Months,', '3', 'Weeks', 'and', '2', 'Days'],\n",
              " ['Harry', 'Potter', 'and', 'the', 'Prisoner', 'of', 'Azkaban'],\n",
              " ['Me', 'and', 'Earl', 'and', 'the', 'Dying', 'Girl'],\n",
              " ['Birdman', 'or', '(The', 'Unexpected', 'Virtue', 'of', 'Ignorance)'],\n",
              " ['Harry', 'Potter', 'and', 'the', 'Goblet', 'of', 'Fire'],\n",
              " ['Star', 'Trek', 'II:', 'The', 'Wrath', 'of', 'Khan'],\n",
              " ['Dawn', 'of', 'the', 'Planet', 'of', 'the', 'Apes'],\n",
              " ['Rise', 'of', 'the', 'Planet', 'of', 'the', 'Apes'],\n",
              " ['The', 'Taking', 'of', 'Pelham', 'One', 'Two', 'Three'],\n",
              " ['One', 'Flew', 'Over', 'the', \"Cuckoo's\", 'Nest'],\n",
              " ['Eternal', 'Sunshine', 'of', 'the', 'Spotless', 'Mind'],\n",
              " ['Once', 'Upon', 'a', 'Time', 'in', 'America'],\n",
              " ['Star', 'Wars:', 'Return', 'of', 'the', 'Jedi'],\n",
              " ['Demon', 'Slayer', 'the', 'Movie:', 'Mugen', 'Train'],\n",
              " ['Lock,', 'Stock', 'and', 'Two', 'Smoking', 'Barrels'],\n",
              " ['Indiana', 'Jones', 'and', 'the', 'Last', 'Crusade'],\n",
              " ['Monty', 'Python', 'and', 'the', 'Holy', 'Grail'],\n",
              " ['The', 'Bridge', 'on', 'the', 'River', 'Kwai'],\n",
              " ['The', 'Treasure', 'of', 'the', 'Sierra', 'Madre'],\n",
              " ['To', 'Be', 'or', 'Not', 'to', 'Be'],\n",
              " ['The', 'Passion', 'of', 'Joan', 'of', 'Arc'],\n",
              " ['Portrait', 'of', 'a', 'Lady', 'on', 'Fire'],\n",
              " ['In', 'the', 'Name', 'of', 'the', 'Father']]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_top_1000_list()[:40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Mem-wyqU1z0f"
      },
      "outputs": [],
      "source": [
        "def label_BIO(_tokens, _NE):\n",
        "    \"\"\"\n",
        "    Generates BIO (Beginning, Inside, Outside) tags for movie titles in the given tokens.\n",
        "\n",
        "    Args:\n",
        "        _tokens (list): List of tokens representing words in a sentence.\n",
        "        _NE (list): List of named entities, where each entity is represented as a list of tokens.\n",
        "\n",
        "    Returns:\n",
        "        list: List of tuples containing tokens and their corresponding BIO tags.\n",
        "\n",
        "    Comments:\n",
        "        - This function searches for movie titles in the tokens and labels them using BIO notation.\n",
        "        - A movie title is considered to be a named entity, where the first word is labeled as 'B-MOV'\n",
        "          (Beginning of a movie title) and subsequent words are labeled as 'I-MOV' (Inside a movie title).\n",
        "        - Non-movie title tokens are labeled as 'O' (Outside any named entity).\n",
        "        - The function iterates through each token in the tokens list, searching for matches in the named entity list.\n",
        "          If a match is found, the corresponding tokens are labeled accordingly in the BIO format.\n",
        "        - It returns a list of tuples, each containing a token and its corresponding BIO tag.\n",
        "    \"\"\"\n",
        "    BIO_for_samples = []\n",
        "\n",
        "    # for token in _tokens: # method 1 # this method needs tokens be unique words in csv file but had some false predictions \n",
        "    #     if token in _NE:\n",
        "    #         # BIO_for_samples.append((token, 'B-MOV'))\n",
        "    #         if (len(BIO_for_samples) == 0): # first named entity\n",
        "    #             BIO_for_samples.append((token, 'B-MOV'))\n",
        "    #         elif BIO_for_samples[-1][1] == 'B-MOV' or BIO_for_samples[-1][1] == 'I-MOV':\n",
        "    #             BIO_for_samples.append((token, 'I-MOV'))\n",
        "    #         else:\n",
        "    #             BIO_for_samples.append((token, 'B-MOV'))\n",
        "    #     else:\n",
        "    #         BIO_for_samples.append((token, 'O'))\n",
        "\n",
        "    i = 0 # method 2\n",
        "    while (i < len(_tokens)):\n",
        "        token = _tokens[i]\n",
        "        is_in_NE = False\n",
        "        for named_entity in _NE:\n",
        "            found = True\n",
        "            if (token == named_entity[0]):\n",
        "                for j in range(1, len(named_entity)):\n",
        "                    # if (_tokens[i + j] == len(_tokens)):\n",
        "                    if (i + j == len(_tokens)):\n",
        "                        found = False\n",
        "                        break\n",
        "                    if (named_entity[j] != _tokens[i + j]):\n",
        "                        found = False\n",
        "                        break\n",
        "                if (found):\n",
        "                    BIO_for_samples.append((token, 'B-MOV'))\n",
        "                    is_in_NE = True\n",
        "                    for j in range(1, len(named_entity)):\n",
        "                        BIO_for_samples.append((_tokens[i + j], 'I-MOV'))\n",
        "                    i = i + len(named_entity)\n",
        "                    break # for named_entity in _NE:\n",
        "\n",
        "        if not is_in_NE:\n",
        "            BIO_for_samples.append((token, 'O'))\n",
        "            i += 1\n",
        "\n",
        "    return BIO_for_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "1UA4HbNA5Fj6"
      },
      "outputs": [],
      "source": [
        "# Don't change this cell\n",
        "def print_BIO_res(_BIO):\n",
        "    for i in range(len(_BIO)):\n",
        "        if _BIO[i][1] == 'B-MOV':\n",
        "            for j in range(i - 7, i + 7):\n",
        "                if _BIO[j][1] == 'O':\n",
        "                    print(_BIO[j][0], end=\" \")\n",
        "                else:\n",
        "                    print(_BIO[j], end=\" \")\n",
        "            print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vrQqvG947sb4"
      },
      "outputs": [],
      "source": [
        "# Don't change this cell\n",
        "def get_data_from_file(_fn):\n",
        "    with open(_fn, 'r') as file:\n",
        "        data = file.read().replace('\\n', ' ')\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdzyVGJ25IBc",
        "outputId": "e1e9336f-2793-40fd-bf4c-855338e9d235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ten Rings is shaping up to overtake ('Black', 'B-MOV') Widow as the biggest film of \n",
            ". With films like Chan ’ s ('Rush', 'B-MOV') Hour ( 1998 ) and Shanghai \n",
            "to find its way into hits like ('The', 'B-MOV') ('Matrix', 'I-MOV') ( 1999 ) and Kill \n",
            "the trend . Jet Li ’ s ('Hero', 'B-MOV') ( 2002 ) and Fearless ( \n",
            "comedies Shaolin Soccer ( 2001 ) and ('Kung', 'B-MOV') ('Fu', 'I-MOV') ('Hustle', 'I-MOV') ( 2004 ) , \n",
            ") , and Donnie Yen ’ s ('Ip', 'B-MOV') ('Man', 'I-MOV') ( 2008 ) . Shang-Chi \n"
          ]
        }
      ],
      "source": [
        "titles_top_1000 = get_top_1000_list()\n",
        "\n",
        "# get text data from a text file\n",
        "# data = get_data_from_file(\"data/article-about-a-genre.txt\")\n",
        "data = get_data_from_file(\"article-about-a-genre.txt\")\n",
        "# tokenize text data\n",
        "tokens = word_tokenize(data)\n",
        "# tag with BIO using the IMDB top 1000 movie title list\n",
        "BIO = label_BIO(tokens, titles_top_1000)\n",
        "\n",
        "print_BIO_res(BIO)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
